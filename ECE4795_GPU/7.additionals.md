# URP
- this section describes how legacy HLSL shaders used in the prior sections can be converted to the new Universal Render Pipeline
- in the original project, install the Universal RP
  - this installs dependencies such as the Core RP Library
- create a Pipeline Asset, which by default creates a Renderer that it links to
- for broken shaders...
  - try reimporting them as assets again
  - replace `#include "UnityCG.cginc"` to `#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"`
  - change `ForwardAdd` tag to
    - `"RenderType" = "Opaque"`
    - `"Render Pipeline" = "UniversalRenderPipeline"`
    - for this reason the prior example for switching between point/directional light by changing tags is no longer valid
  - replace built-in lighting constructs with URP constants
    - for light-related constants, URP has replace with a `Light` struct with `direction`, `distanceAttenuation`, `shadowAttenuation`, `color` properties
    - note also that this info comes from the `Lighting.hlsl` file in the URP package that is imported in the `#include` above
    - for the main light (assumed to be directional), there is a `GetMainLight()`
    - for other lights dependent on the object of interest, there is a `GetAdditionalPerObjectLight(int perObjectLightIndex, float3 positionWS)`
      - this function reads the `_AdditionalLightsBuffer` which is an array of `Light`s
    - note the `perObjectLightIndex` is abstracted once again by the specific method for packing light indices in the underlying platform
      - the source is `unity_LightIndices` array, which is packed differently between mobile, desktop, etc.
      - to get the index through uniform interface, use `GetPerObjectLightIndex(uint index)` where `index` is the raw index like 0, 1, ...
    - 
  - the URP takes all lights and processes them in one pass, different fron the built-in shader that use separate passes
- note that `float` can be rewritten as `real` in order to leverage shader quality settings
  - *ex.* `real4` can be written as `float4`, `half4`, etc. depending on how Unity is configured

# DIY Built-in Pipeline Post-Processing
- the main puropse is to show implementation of the built-in post-processing stack, don't actually use it in production
- post processing shader setup
  - structures
    - ```
      struct appdata_img {
        float4 vertex: POSITION;
        half2 texcoord: TEXCOORD0;
        UNITY_VERTEX_INPUT_INSTANCE_ID // macro for including instance ID
      }
      ```
    - ```
      struct v2f_img {
        float4 pos: SV_POSITION;
        half2 uv: TEXCOORD0;
        UNITY_VERTEX_INPUT_INSTANCE_ID // macro for including instance  ID
        UNITY_VERTEX_OUTPUT_STEREO // macro for VR related settings (stereo view)
      }
      ```
  - vertex shader
    ```
    v2f_img vert_img( appdata_img v ) {
        v2f_img o;
        UNITY_INITIALIZE_OUTPUT(v2f_img, o);
        UNITY_SETUP_INSTANCE_ID(v);
        UNITY_INITIALIZE_VERTEX_OUTPUT_STEREO(o);
        o.pos = UnityObjectToClipPos(v.vertex);
        o.uv = v.texcoord;
        return o;
    }
    ```
  - fragment shader takes `v2f_img` and outputs `COLOR`
  - similar to previous shaders, use `#pragma vertex` and `#pragma fragment` to locate shader programs
  - overall shader visibility (prevent it from being assigned to some material)
    - `Shader "Hidden/<my_package ...>" { ... }`
  - shader pass properties
    - `ZTest Always Cull Off ZWrite Off`
- using the shader as post processing
  - on the camera's game object, attach script
    ``` c#
    public Shader pp;
    public Material ppMat;

    void Start() {
        pp = Shader.Find("Hidden/<my_package ...>");
        ppMat = new Material(pp);
    }

    void Update() {
        // example parameter update
        // pp.setFloat("_Param", 0);
    }

    // insert post processing material to the pipeline
    void OnRenderImage(RenderTexture src, RenderTexture dst) {
        Graphics.Blit(src, dest, ppMat);
    }
    ```
## Using Camera Values in Post Processing Shader
- use the `_CameraDepthNormalsTexture` as provided by Unity in `UnityCG.cginc`
  - depth can be extracted via `DecodeDepthNormal(float4 encoded, out float depth, out float3 normal)`
    - note that this decoded depth is still non-linear, this is because the compression preserves shallow depth values with more precision
    - to get linear depth, use `LinearEyeDepth(float z)` to retrieve actual linear depth from decoded depth
  - one technique when calling this kind of function is to put `out` in comments to avoid confusion
    - *ex.* `DecodeDepthNormal(enc, /*out*/ depth, /*out*/ normal)`
  
# Deferred Rendering Simplified Demo
- run a G-buffer pass first that write all relevant information (F, depth, etc.)
- then, the lighting pass takes the G-buffer and renders the correct output
## Shader Implementation
- required properties
  - `_DiffColor("Diff Color", Color) = (1, 1, 1, 1)`
  - `_SpecColor("Spec Color", Color) = (1, 1, 1, 1)`
    > the tutorial uses a bunch of other C# driven properties that are not defined here but do appear as variables in the `pass` itself
    > for some reason, only the two properties above are required to be defined explicitly
- unity calls `OnPreCull` before the camera does any culling, and `OnPreRender` after the camera completes culling, and `OnPostRender` after the camera renders the scene
  - the documentation site shows an example of reverting render settings between these lifecycle events
  - ```c#
    private bool revertFogState = false;

    void OnPreRender()
    {
        revertFogState = RenderSettings.fog;
        RenderSettings.fog = enabled;
    }

    void OnPostRender()
    {
        RenderSettings.fog = revertFogState;
    }
    ```
  - in the tutorial, the `OnPreRender` event is used to inject properties to the shader

# Unity's Built-in Post-Processing Stack
- requires the Post-Processing package for Unity's built-in pipeline
- note that after installation various shader errors can be fixed just by reimporting
- post processing volume
  - does not need to be on the same object as the camera
  - contains certain `overrides` that can be controlled
  - is inherently a volume in the object space (in the Unity Scene sense, not in the shader sense) where the post-processing effects take place
  - there can be multiple volumes in a scene
  - there can be multiple volumes on the same object
  - volumes use a stack structure to represent the pipeline (the order of volumes and the order of overrides within each volume are both configurable)
## Built-in Post-Proc. Shaders
- setup
  - imports: `StdLib.hlsl`
    - the package contains
      - a version of `a2f` called `AttributesDefault`
        - `.vertex : POSITION`
      - a version of `v2f` called `VaryingsDefault` 
        - `.vertex : SV_POSITION`
        - `.texcoord : TEXCOORD0`
        - `.texcoordStereo : TEXCOORD1`
      - a vertex shader `VertDefault` going from `AttributesDefault` to `VaryingsDefault`
- the overall shader
```
// note usage of Hidden because this is a post-processing shader
Shader "Hidden/Custom/<your_stack_name>" {

    // note this section is above the SubShader section
    HLSLINCLUDE

    #include "Packages/com.unity.postprocessing/PostProcessing/Shaders/StdLib.hlsl"

    // note this is not sampler2D form
    // this is a macro that defines necessary properties for the main texture (see Frag)
    TEXTURE2D_SAMPLER2D(_MainTex, sampler_MainTex);
    float _Foo;
    // ...  other parameters 

    // note this writes to SV_TARGET instead of COLOR
    float4 Frag(VaryingsDefault i) : SV_TARGET {
        
        // ... 

        // if needed, sample texture using the SAMPLE_TEXTURE2D(<texture>, <sampler>, <uv>) macro

        // finally, return a float4 just as before
    }

    ENDHLSL

    // selects the shaders from above
    SubShader {
        Cull Off ZWrite Off ZTest Always
        pass {
            HLSLPROGRAM
              #pragma vertex VertDefault
              #pragma fragment Frag
            ENDHLSL
        }
    }
}
```
- Unity's macros change between versions and different demos, the above is just some example
  - the goal is for Unity to switch the underlying graphics implementation that may associate with different functions
- the post processing override is associated with two other scripts binding the shader to the stack override
``` c#

using System;
using UnityEngine;
using UnityEngine.Rendering.PostProcessing;

[Serializable]
[PostProcess(typeof(CustomRenderer), PostProcessEvent.AfterStack, "Custom/CustomEffecttack")]
public sealed class CustomEffectStack : PostProcessEffectSettings {
    [Tooltip("This is a parameter")]
    public FloatParamter foo =  new FloatParamter { value =  1f };
}
```
``` c#
public sealed class CustomRenderer : PostProcessEffectRenderer<CustomEffectStack> {
    public override void Render (PostProcessRenderContext context) {
        var sheet = context.propertySheets.Get(Shader.Find("Hidden/Custom/<your_stack_name>"));
        sheet.properties.SetFloat("_Foo", settings.foo);

        // note this is similar to the previous section's "OnPreRender" step
        context.command.BlitFullscreenTriangle(context.source, context.destination, sheet, 0);
    }
}
```

# URP Post Processing Changes
- as of 2022 (URP 14.0.3), URP does not support custom post-processing
- to implement post processing in URP, scriptable RP needs to be explored