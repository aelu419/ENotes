- [Book](#book)
- [What is a Type System](#what-is-a-type-system)
  - [Definition and Properties](#definition-and-properties)
  - [Application of Type Checking](#application-of-type-checking)
- [Mathematical Preliminaries](#mathematical-preliminaries)
  - [Basics](#basics)
  - [Ordered Sets](#ordered-sets)
  - [Sequences](#sequences)
  - [Induction](#induction)

# Book
- Benjamin C. Pierce, *Types and Programming Languages*

# What is a Type System

## Definition and Properties
- SWE uses formal methods to ensure programs behave correctly
  - particularly, *lightweight* formal methods can be automated
    - *ex.* model checkers check for possible errors when running in some finite state systems like chips or comm. protocols
    - *ex.2* runtime monitoring allows for systems to check if components are working correctly
    - *ex.3* type systems!
- *def.*
  - tractable, syntactic method
  - for proving the absence of program behaviors
  - by classifying phrases according to the values they (the behaviors) compute
  - this definition is geared towards programs when **types** as a concept is also used in logic, philosophy, etc.
- type systems can be statifc/dynamic
  - **static** type systems perform checks before run time
    - it "simulates" what runtime scenarios might be in a cheap manner
    - it is neccessarily *conservative*, meaning it can prove what is not there, but can't prove what *is* there
  - **dynamic/latent** type systems perform checks during run time
- a type system guarantees that
  - a *well-typed* program is free from *certain kinds of* issues
    - namely, run-time type errors
    - what a language considers as a run-time type error is dependent on design (languages where types can freely convert to each other considers less scenarios as erroneous)
- **type annotations**
  - provide user control on what the type checker checks for
  - type checkers aim to approach **proof checker** functionality with reasonably light annotations in the code
- type systems encourage more abstraction (separation between interface and implementation), which is preferable for large-scale programs as well as libraries

## Application of Type Checking
- the notion of **safe language**
  - depends on the language community and the design of the language itself
  - generally, a safe language protects its own abstractions
    - this means, a user can use abstractions on the abstract level without going into implementation level
    - i.e. a safe language is *intuitive*
  - dynamically typed languages *can* be safe as long as they throw exceptions the illegal operation happens
  - *ex.* C/C++ is not safe, Java is safe
  - alternative views on language safety includes
    - safe languages are platform-agnostic (*i.e.* portable, completely defined by their user manual)
    - languages are safe as long as they trap illegal operations (*ex.* acessing beyond array boundaries)
- static typing does not guarantee runtime safety: *ex.* explicit narrowing in Java
- type information is useful for optimization
- type system design is usually determined at initial stages of language design
  - it is difficult and rare for a language to change its type system drastically after everything else settles

# Mathematical Preliminaries

## Basics
- a one-place relation is called a *predicate*
  - predicate $P \subseteq S$, and $P(s)$ is said to be "True" if $s \in P$
- a two-place relation uses notation $sRt$ instead of $(s, t) \in R$
  - for domain $dom(R) = {s}$ and codomain $range(R) = {t}$ for $(s, t) \in R$
- higher n-place relations use $(s_1, ..., s_n) \in R$ when these elements (in that order) are related
- a partial function has $aRb \land aRc \to b = c$ (same output per input)
  - note that failing does not automatically make a function partial, if the codomain already includes explicit failure states
- a function (*i.e.* total function) has the previous requirement, plus the extra requirement that $dom(R)=S$ (every input returns something)
- a predicate $P$ preserves a relation $R$ if
  - for every $s R s'$, $P(s)$ and $P(s')$

## Ordered Sets
- a **preorder** is reflexive and transitive
  - a **partial order** is a preorder that is also antisymmetric ($aRb \land bRa \to a=b$)
    - a **total order** is a partial order where every member of the set is comparable to each other
- a **least upper bound** (join) $j$ for $s, t$ is where
  - $s \leq j, t \leq j$
  - $\forall k, s \leq k \to t \leq k$
- a **greatest lower bound** (meet) is similarly defined when all comparisons are swapped
- an **equivalence** is reflexive, transitive, and symmetric
- the **reflexive closure** $R'$ is the smallest reflexive relation that includes $R$
  - the **transitive closure** is similarly defined, denoted $R^+$
  - the **transitive and reflexive closure** is similarly defined, denoted $R^*$
- a **decreasing chain** on a preorder is a sequence where every element is *strictly* less than the previous
- a **well founded** preorder on set $S$ does not have an infinite decreasing chain
  - alternately, $S$ itself is called a **well founded set**

## Sequences
- the **permutation** of another sequence is a sequence with the same elements, without requirements on order
- series $a$ flattens when appended to another series
  - *ex.* $0, a, 1$ is $0, 1, 2, 3, 1$ for $a = 1, 2, 3$
  - this is just a notational choice
- $|a|$ is the length of a finite sequence

## Induction
- weak induction: if $P(0)$, $\forall i: P(i) \to P(i+1)$, then $\forall n: P(n)$
- strong induction: if $\forall n: (\forall i < n: P(i)) \to P(n)$, then $\forall n: P(n)$
- **lexicographic order** (dictionary order) on pairs of natural numbers
  - $(m, n) \leq (m', n') \iff (m < m') \lor (m = m' \land n \leq n')$
  - *i.e.* sort by left index first, then right
- **lexicographic induction**:
  - if $\forall (m, n): (\forall (m', n') < (m, n): P(m, n)) \to P(m, n)$, then $\forall (m, n): P(m, n)$
  - this is basically strong induction but with index pairs
- the above pattern for pairs generalizes to n-tuples